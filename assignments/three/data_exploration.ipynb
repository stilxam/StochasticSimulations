{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "\n",
    "import sns\n",
    "from scipy import stats\n",
    "from tabulate import tabulate\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Preprocessing the data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def data_loading():\n",
    "    \"\"\"\n",
    "    Load the data from the excel file and preprocess it.\n",
    "    \n",
    "    Returns:\n",
    "    - data (pd.DataFrame): Preprocessed data.\n",
    "    \"\"\"\n",
    "    # Load the data from the excel file\n",
    "    data = pd.read_excel('gasstationdata33.xlsx')\n",
    "    \n",
    "    # Drop the 'Unnamed: 0' column\n",
    "    data = data.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "    data = pd.DataFrame(data)\n",
    "    \n",
    "    arrivals_datetime = [arrival.to_pydatetime() for arrival in data[\"Arrival Time\"]]\n",
    "\n",
    "    data[\"Interarrival Times\"] = data[\"Arrival Time\"].diff().dt.total_seconds().fillna(0)\n",
    "    \n",
    "\n",
    "    # Calculate the hour of the day\n",
    "    data['Arrival Time (H)'] = data['Arrival Time'].dt.hour\n",
    "\n",
    "    # replace nan values in Parking preference with None\n",
    "    data['Parking preference'] = data['Parking Preference'].fillna('None')\n",
    "\n",
    "    # fix this mask\n",
    "    data[\"Shope-time-no-zero\"] = data[data[\"Shop time\"] > 0 ][\"Shop time\"]\n",
    "    \n",
    "    # Convert the attributes to minutes\n",
    "    attributes = ['Service time Fuel', 'Shop time', 'Service time payment', 'Interarrival Times', 'Shope-time-no-zero']\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = data_loading()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# calculate the test statistics such as mean, std , skewness, kurtosis, median, mode, range, min, max, 25th percentile, 50th percentile, 75th percentile of the payment service time column\n",
    "def calculate_statistics(data, attributes):\n",
    "    \"\"\"\n",
    "    Calculate the test statistics such as mean, std , skewness, kurtosis, median, mode, range, min, max, 25th percentile, 50th percentile, 75th percentile of the payment service time.\n",
    "    \n",
    "    Args:\n",
    "    - data (pd.DataFrame): Preprocessed data.\n",
    "    \n",
    "    Returns:\n",
    "    - statistics (pd.DataFrame): Dataframe of summary statistics.\n",
    "    \"\"\"\n",
    "    # Calculate the test statistics\n",
    "    statistics = [{\n",
    "        'Mean': data[attribute].mean(),\n",
    "        'Std': data[attribute].std(),\n",
    "        'Skewness': data[attribute].skew(),\n",
    "        'Kurtosis': data[attribute].kurtosis(),\n",
    "        'Median': data[attribute].median(),\n",
    "        'Mode': data[attribute].mode().values[0],\n",
    "        'Range': data[attribute].max() - data[attribute].min(),\n",
    "        'Min': data[attribute].min(),\n",
    "        'Max': data[attribute].max(),\n",
    "        '25th Percentile': data[attribute].quantile(0.25),\n",
    "        '50th Percentile': data[attribute].quantile(0.50),\n",
    "        '75th Percentile': data[attribute].quantile(0.75)\n",
    "    } for attribute in attributes]\n",
    "    \n",
    "    \n",
    "    # Convert the statistics list to a DataFrame for easier manipulation\n",
    "    statistics = pd.DataFrame(statistics, index=attributes).T\n",
    "    # round to 4 sf\n",
    "    statistics = statistics.round(4)\n",
    "    \n",
    "        \n",
    "    return tabulate(statistics, headers='keys', tablefmt='pretty')\n",
    "        \n",
    "    \n",
    "    \n",
    "    # return tabulate(statistics.items(), headers=['Statistics', attribute], tablefmt='pretty')\n",
    "    # return statistics\n",
    "\n",
    "statistics = calculate_statistics(data, ['Service time Fuel', 'Shop time', 'Service time payment', 'Interarrival Times', \"Arrival Time (H)\"])\n",
    "# print(statistics)\n",
    "# print(tabulate(statistics.items(), headers=['Statistics', 'Value'], tablefmt='fancy_grid'))\n",
    "\n",
    "print(statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2, figsize=(10, 10))\n",
    "\n",
    "\n",
    "axs[0,1].hist(data[\"Service time Fuel\"], bins=30)\n",
    "axs[0,1].set_title(\"Service time Fuel\")\n",
    "\n",
    "axs[1,0].hist(data[\"Shop time\"], bins=30)\n",
    "axs[1,0].set_title(\"Shop time\")\n",
    "\n",
    "axs[1,1].hist(data[\"Service time payment\"], bins=18)\n",
    "axs[1,1].set_title(\"Service time payment\")\n",
    "\n",
    "axs[2,0].hist(data[\"Interarrival Times\"], bins=30)\n",
    "axs[2,0].set_title(\"Interarrival Times\")\n",
    "\n",
    "# axs[0,0].hist(interarrival_times, bins=30)\n",
    "# axs[1].hist(fuel_time, bins=20)\n",
    "# axs[2].hist(shop_time, bins= math.floor(np.sqrt(len(shop_time))))\n",
    "# axs[2].set_xlim(0, 200)\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "__Testing underlying distributions__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# conver the shop time into a binary variable\n",
    "shop_time = data[\"Shop time\"]\n",
    "shop_time = shop_time.apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "count_1 = shop_time[shop_time == 1].count()\n",
    "count_0 = shop_time[shop_time == 0].count()\n",
    "\n",
    "percentage_1 = count_1 / (count_1 + count_0)\n",
    "percentage_0 = count_0 / (count_1 + count_0)\n",
    "\n",
    "# print (percentage_0, percentage_1)\n",
    "\n",
    "\n",
    "\n",
    "def calculate_shop_probabilities(data):\n",
    "    \"\"\"\n",
    "    Calculate the probabilities of having a shop time and the conditional probabilities of having a shop time or not.\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): DataFrame containing shop times.\n",
    "    \n",
    "    Returns:\n",
    "    - probabilities (dict): Dictionary containing calculated probabilities.\n",
    "    \"\"\"\n",
    "    shop_time = data[\"Shop time\"]\n",
    "    total_len = len(shop_time)\n",
    "    has_shop_time = shop_time[shop_time > 0]\n",
    "    \n",
    "    probabilities = {\n",
    "        \"probability_of_shop_time\": len(has_shop_time) / total_len,\n",
    "        \"probability_of_no_shop_time\": 1 - len(has_shop_time) / total_len,\n",
    "        \"count_total\": total_len,\n",
    "        \"count_shop_time\": len(has_shop_time),\n",
    "    }\n",
    "    \n",
    "    \n",
    "    return probabilities\n",
    "\n",
    "def test_binomial_distribution(probabilities, alternative=\"two-sided\", p_value = 0.05):\n",
    "    \"\"\"\n",
    "    Test for binomial distribution of shop time.\n",
    "    \n",
    "    Parameters:\n",
    "    - probabilities (dict): Dictionary containing calculated probabilities.\n",
    "    - total_len (int): Total number of shop times.\n",
    "    \n",
    "    Returns:\n",
    "    - test_results (dict): Dictionary containing test results.\n",
    "    \"\"\"\n",
    "    test_results = {\n",
    "        \"test_for_shop_time_binom\": stats.binomtest(\n",
    "            probabilities[\"count_shop_time\"],\n",
    "            probabilities[\"count_total\"],\n",
    "            p=probabilities[\"probability_of_shop_time\"],\n",
    "            alternative=alternative\n",
    "        ),\n",
    "    }\n",
    "    \n",
    "    formatted_results = [{\"Test\": key, \"Result\": value, \"Significance\":value.pvalue>=p_value} for key, value in test_results.items()]\n",
    "    \n",
    "    # Use tabulate to format the output\n",
    "    print(tabulate(formatted_results, headers=\"keys\", tablefmt=\"pretty\"))\n",
    "    return test_results\n",
    "\n",
    "\n",
    "# Calculate the probabilities\n",
    "shop_probabilities = calculate_shop_probabilities(data)\n",
    "pprint(shop_probabilities)\n",
    "# test_results = test_binomial_distribution(shop_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calculate_preference_probabilities(data):\n",
    "    \"\"\"\n",
    "    Calculate the probabilities of having a parking preference and the conditional probabilities of preferring right or left.\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): DataFrame containing parking preferences.\n",
    "    \n",
    "    Returns:\n",
    "    - probabilities (dict): Dictionary containing calculated probabilities.\n",
    "    \"\"\"\n",
    "    preferences = data[\"Parking Preference\"]\n",
    "    total_len = len(preferences)\n",
    "    has_preference = preferences[(preferences == \"Right\") | (preferences == \"Left\")]\n",
    "    \n",
    "    probabilities = {\n",
    "        \"probability_of_preference\": len(has_preference) / total_len,\n",
    "        \"probability_of_no_preference\": 1 - len(has_preference) / total_len,\n",
    "        \"probability_of_right\": has_preference[has_preference == \"Right\"].count() / len(has_preference),\n",
    "        \"probability_of_left\": has_preference[has_preference == \"Left\"].count() / len(has_preference),\n",
    "        \"count_total\": total_len,\n",
    "        \"count_preference\": len(has_preference),\n",
    "        \"count_right\": has_preference[has_preference == \"Right\"].count(),\n",
    "        \"count_left\": has_preference[has_preference == \"Left\"].count()\n",
    "        \n",
    "    }\n",
    "    \n",
    "    return probabilities\n",
    "\n",
    "def test_binomial_distribution(probabilities, alternative=\"two-sided\", p_value = 0.05):\n",
    "    \"\"\"\n",
    "    Test for binomial distribution of preference and left/right parking preferences.\n",
    "    \n",
    "    Parameters:\n",
    "    - probabilities (dict): Dictionary containing calculated probabilities.\n",
    "    - total_len (int): Total number of parking preferences.\n",
    "    \n",
    "    Returns:\n",
    "    - test_results (dict): Dictionary containing test results.\n",
    "    \"\"\"\n",
    "    test_results = {\n",
    "        \"test_for_preference\": stats.binomtest(\n",
    "            probabilities[\"count_preference\"],\n",
    "            probabilities[\"count_total\"],\n",
    "            p=probabilities[\"probability_of_preference\"],\n",
    "            alternative=alternative\n",
    "        ),\n",
    "        \"test_for_left\": stats.binomtest(\n",
    "            probabilities[\"count_left\"],\n",
    "            (probabilities[\"count_preference\"]),\n",
    "            p=probabilities[\"probability_of_left\"],\n",
    "            alternative=alternative\n",
    "            \n",
    "        ),\n",
    "        \"test_for_right\": stats.binomtest(\n",
    "            probabilities[\"count_right\"],\n",
    "            (probabilities[\"count_preference\"]),\n",
    "            p=probabilities[\"probability_of_right\"],\n",
    "            alternative=alternative\n",
    "    \n",
    "        ),\n",
    "    }    \n",
    "    \n",
    "    formatted_results = [{\"Test\": key, \"Result\": value, \"Significance\":value.pvalue>=p_value} for key, value in test_results.items()]\n",
    "    \n",
    "    # Use tabulate to format the output\n",
    "    print(tabulate(formatted_results, headers=\"keys\", tablefmt=\"pretty\"))\n",
    "    return test_results\n",
    "\n",
    "\n",
    "# Calculate the probabilities\n",
    "preferences_probabilities = calculate_preference_probabilities(data)\n",
    "test_results = test_binomial_distribution(preferences_probabilities)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def analyze_distributions(data, list_of_attributes):\n",
    "    \"\"\"\n",
    "    Analyze the distributions of the given attributes in the data.\n",
    "    :param data: \n",
    "    :param list_of_attributes: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    output_parameters = {}\n",
    "\n",
    "    # when calculating distribution of shop time we remove non zeroes\n",
    "    for attribute in list_of_attributes:\n",
    "        if attribute == \"Shop time\":\n",
    "            data = data[data[attribute] > 0]\n",
    "        \n",
    "        output_parameters[attribute] = {}\n",
    " \n",
    "        \n",
    "        # m = np.mean(data[attribute])\n",
    "        # fit_uniform_dist = stats.uniform(loc=0, scale=2 * m)\n",
    "        \n",
    "        fit_uniform_dist = stats.uniform(loc=(data[attribute].min()), scale=data[attribute].max() - data[attribute].min())\n",
    "        \n",
    "        test = stats.kstest(data[attribute], fit_uniform_dist.cdf)\n",
    "\n",
    "        \n",
    "        p_value = test[1]\n",
    "        fit_status = \"Good fit\" if p_value > 0.05 else \"Bad fit\"\n",
    "        results.append([attribute, \"Uniform Distribution\", fit_status, p_value])\n",
    "        output_parameters[attribute][\"Uniform Distribution\"] = ({\n",
    "            \"loc\" : data[attribute].min(),\n",
    "            \"scale\": data[attribute].max() - data[attribute].min()\n",
    "        })\n",
    "        \n",
    "\n",
    "        # Exponential distribution\n",
    "        m1 = np.mean(data[attribute])\n",
    "        fit_exponential_dist = stats.expon(scale=1 / m1)\n",
    "        test = stats.kstest(data[attribute], fit_exponential_dist.cdf)\n",
    "        p_value = test[1]\n",
    "        fit_status = \"Good fit\" if p_value > 0.05 else \"Bad fit\"\n",
    "        results.append([attribute, \"Exponential Distribution\", fit_status, p_value])\n",
    "        output_parameters[attribute][\"Exponential Distribution\"] = ({\n",
    "            \"estimated_lambda\": 1 / m1\n",
    "        })\n",
    "\n",
    "        \n",
    "        # Gamma distribution\n",
    "        m2 = np.mean([x**2 for x in data[attribute]])\n",
    "        est_beta = m1 / (m2 - m1**2)\n",
    "        est_alpha = m1 * est_beta\n",
    "        fit_gamma_dist = stats.gamma(a=est_alpha, scale=1 / est_beta)\n",
    "        test = stats.kstest(data[attribute], fit_gamma_dist.cdf)\n",
    "        p_value = test[1]\n",
    "        fit_status = \"Good fit\" if p_value > 0.05 else \"Bad fit\"\n",
    "        results.append([attribute, \"Gamma Distribution\", fit_status, p_value])\n",
    "        output_parameters[attribute][\"Gamma Distribution\"] =({\n",
    "            \"estimated_alpha\": est_alpha,\n",
    "            \"estimated_beta\": est_beta\n",
    "        })\n",
    "\n",
    "        # Poisson distribution\n",
    "        fi_poisson_dist = stats.poisson(mu=m1)\n",
    "        test = stats.kstest(data[attribute], fi_poisson_dist.cdf)\n",
    "        p_value = test[1]\n",
    "        fit_status = \"Good fit\" if p_value > 0.05 else \"Bad fit\"\n",
    "        results.append([attribute, \"Poisson Distribution\", fit_status, p_value])\n",
    "        \n",
    "        output_parameters[attribute][\"Poisson Distribution\"]=({\n",
    "            \"estimated_lambda\": m1\n",
    "        })\n",
    "\n",
    "        # Normal distribution\n",
    "        estimated_std = m2 - m1**2\n",
    "        fit_normal_dist = stats.norm(loc=m1, scale=estimated_std)\n",
    "        test = stats.kstest(data[attribute], fit_normal_dist.cdf)\n",
    "        p_value = test[1]\n",
    "        fit_status = \"Good fit\" if p_value > 0.05 else \"Bad fit\"\n",
    "        results.append([attribute, \"Normal Distribution\", fit_status, p_value])\n",
    "        \n",
    "        output_parameters[attribute][\"Normal Distribution\"]=({\n",
    "            \"estimated_mean\": m1,\n",
    "            \"estimated_std\": estimated_std\n",
    "        })\n",
    "\n",
    "    # Convert the results list to a DataFrame for easier manipulation\n",
    "    results_df = pd.DataFrame(results, columns=[\"Attribute\", \"Distribution\", \"Fit Status\", \"P-value\"])\n",
    "\n",
    "    return results_df, output_parameters\n",
    "\n",
    "list_of_attributes = [\"Service time Fuel\", \"Service time payment\", \"Interarrival Times\", \"Shop time\"]\n",
    "fit_status, parameters = analyze_distributions(data, list_of_attributes)\n",
    "print(tabulate(fit_status, headers='keys', tablefmt='pretty'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def selecting_distribution(fit_status, parameters):\n",
    "    \"\"\"\n",
    "    Select the best distribution for each attribute.\n",
    "    \n",
    "    Parameters:\n",
    "    - fit_status (pd.DataFrame): DataFrame containing the results of the distribution analysis.\n",
    "    - parameters (dict): Dictionary containing the parameters of the distributions.\n",
    "    \n",
    "    Returns:\n",
    "    - selected_distributions (dict): Dictionary containing the selected distributions for each attribute.\n",
    "    \"\"\"\n",
    "    selected_distributions = {}\n",
    "    \n",
    "    # Filter the parameters DataFrame to only include good fits\n",
    "    good_fits = fit_status[fit_status[\"Fit Status\"] == \"Good fit\"]\n",
    "    \n",
    "    # Create a dictionary to store the distribution type and p-value for each attribute\n",
    "    dist_type = {}\n",
    "    \n",
    "    # Iterate over the good fits\n",
    "    for index, row in good_fits.iterrows():\n",
    "        # If the attribute is not in the dictionary, add it\n",
    "        if row[\"Attribute\"] not in dist_type:\n",
    "            dist_type[row[\"Attribute\"]] = (row[\"Distribution\"], row[\"P-value\"])\n",
    "        # If the p-value is higher than the current p-value, update the distribution type\n",
    "        else:\n",
    "            if row[\"P-value\"] > dist_type[row[\"Attribute\"]][1]:\n",
    "                dist_type[row[\"Attribute\"]] = (row[\"Distribution\"], row[\"P-value\"])\n",
    "    \n",
    "    # Create a dictionary to store the parameters of the selected distributions\n",
    "    results = {}\n",
    "    \n",
    "    # Iterate over the distribution types\n",
    "    for attribute, value in dist_type.items():\n",
    "        # Add the distribution type and parameters to the results dictionary\n",
    "        results[attribute] = (value[0], parameters[attribute][value[0]])\n",
    "    \n",
    "    # Return the selected distributions\n",
    "    return results\n",
    "\n",
    "# Select the best distribution for each attribute\n",
    "selected_distributions = selecting_distribution(fit_status, parameters)\n",
    "\n",
    "pprint(selected_distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(data[\"Service time Fuel\"], density=True)\n",
    "ax.set_xlabel(\"Service Time Fuel (s)\")\n",
    "ax.set_ylabel(\"Density\")\n",
    "x = np.linspace(data[\"Service time Fuel\"].min(), data[\"Service time Fuel\"].max())\n",
    "y = stats.gamma(a=parameters[\"Service time Fuel\"][\"Gamma Distribution\"][\"estimated_alpha\"], scale=1 / parameters[\"Service time Fuel\"][\"Gamma Distribution\"][\"estimated_beta\"]).pdf(x)\n",
    "ax.plot(\n",
    "    x,\n",
    "    y,\n",
    "    label=\"Estimated Gamma Distribution\",\n",
    "    color=\"orange\"\n",
    " )\n",
    "  # $\\alpha$ \"+ f\"= {round(parameters['Service time Fuel']['Gamma Distribution']['estimated_alpha'])}, $\\beta$$\"+f\" = {round(parameters['Service time Fuel']['Gamma Distribution']['estimated_beta'])}\"),\n",
    "ax.legend(loc=\"upper right\")\n",
    "fig.suptitle(\"Service Time Fuel Distribution\")\n",
    "fig.savefig(\"/graphs/EDA/service_time_fuel_distribution.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "observed_frequencies = data['Service time payment'].value_counts().sort_index()\n",
    "\n",
    "# λ for the Poisson distribution from the data\n",
    "lambda_poisson = data['Service time payment'].mean()\n",
    "\n",
    "# Re-create the Poisson distribution object\n",
    "poisson_dist = stats.poisson(mu=lambda_poisson)\n",
    "\n",
    "# Recalculate the expected Poisson frequencies for each unique value\n",
    "expected_frequencies_poisson = poisson_dist.pmf(observed_frequencies.index) * len(data)\n",
    "\n",
    "# Create a bar chart for the observed frequencies\n",
    "# plt.figure(figsize=(14, 7))\n",
    "n = len(data['Service time payment'])\n",
    "ax.bar(observed_frequencies.index, observed_frequencies/n, label='Observed Frequencies')\n",
    "\n",
    "# Add a scatter plot for the expected Poisson frequencies\n",
    "ax.scatter(observed_frequencies.index, expected_frequencies_poisson/n, color='orange', label='Expected Poisson Density', zorder=2)\n",
    "\n",
    "# ax.hist(data[\"Service time payment\"],bins=20, density=True)\n",
    "ax.set_xlabel(\"Service Time Payment (s)\")\n",
    "ax.set_ylabel(\"Density\")\n",
    "\n",
    "ax.legend(loc=\"upper right\")\n",
    "\n",
    "fig.suptitle(\"Service Time Payment Distribution\")\n",
    "fig.savefig(\"/graphs/EDA/service_time_payment_distribution.png\")\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "shop_data = data[data[\"Shop time\"] > 0]\n",
    "\n",
    "ax.hist(shop_data[\"Shop time\"], density=True )\n",
    "ax.set_xlabel(\"Shop Time (s)\")\n",
    "ax.set_ylabel(\"Density\")\n",
    "# plot the gamma distribution\n",
    "x = np.linspace(shop_data[\"Shop time\"].min(), shop_data[\"Shop time\"].max())\n",
    "y = stats.gamma(a=parameters[\"Shop time\"][\"Gamma Distribution\"][\"estimated_alpha\"], scale=1 / parameters[\"Shop time\"][\"Gamma Distribution\"][\"estimated_beta\"]).pdf(x)\n",
    "\n",
    "ax.plot(\n",
    "    x,\n",
    "    y,\n",
    "    label=\"Estimated Gamma Distribution\",\n",
    "    color=\"orange\"\n",
    " )\n",
    "ax.legend(loc=\"upper right\")\n",
    "\n",
    "fig.suptitle(\"Shop Time Distribution\")\n",
    "fig.savefig(\"/graphs/EDA/shop_time_distribution.png\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist( data[\"Interarrival Times\"], density=True)\n",
    "ax.set_xlabel(\"Interarrival Times (s)\")\n",
    "ax.set_ylabel(\"Density (s)\")\n",
    "\n",
    "x = np.linspace(data[\"Interarrival Times\"].min(), data[\"Interarrival Times\"].max())\n",
    "y = stats.gamma(a=parameters[\"Interarrival Times\"][\"Gamma Distribution\"][\"estimated_alpha\"], scale=1 / parameters[\"Interarrival Times\"][\"Gamma Distribution\"][\"estimated_beta\"]).pdf(x)\n",
    "\n",
    "ax.plot(\n",
    "    x,\n",
    "    y,\n",
    "    label=\"Estimated Gamma Distribution\",\n",
    "    color=\"orange\"\n",
    " )\n",
    "ax.legend(loc=\"upper right\")\n",
    "\n",
    "fig.suptitle(\"Interarrival Times Distribution\")\n",
    "fig.savefig(\"/graphs/EDA/interarrival_times_distribution.png\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# SPLOM\n",
    "fig, axs = plt.subplots(4, 4, figsize=(25, 25))\n",
    "\n",
    "\n",
    "axs[0,0].hist(data[\"Service time Fuel\"], density=True)\n",
    "axs[0,0].set_xlabel(\"Service Time Fuel (s)\")\n",
    "axs[0,0].set_ylabel(\"Density\")\n",
    "x = np.linspace(data[\"Service time Fuel\"].min(), data[\"Service time Fuel\"].max())\n",
    "y = stats.gamma(a=parameters[\"Service time Fuel\"][\"Gamma Distribution\"][\"estimated_alpha\"], scale=1 / parameters[\"Service time Fuel\"][\"Gamma Distribution\"][\"estimated_beta\"]).pdf(x)\n",
    "axs[0,0].plot(\n",
    "    x,\n",
    "    y,\n",
    "    label=\"Estimated Gamma Distribution\",\n",
    "    color=\"orange\"\n",
    " )\n",
    "  # $\\alpha$ \"+ f\"= {round(parameters['Service time Fuel']['Gamma Distribution']['estimated_alpha'])}, $\\beta$$\"+f\" = {round(parameters['Service time Fuel']['Gamma Distribution']['estimated_beta'])}\"),\n",
    "axs[0,0].legend(loc=\"upper right\")\n",
    "\n",
    "\n",
    "axs[0,1].scatter(data[\"Service time Fuel\"], data[\"Service time payment\"])\n",
    "axs[0,1].set_xlabel(\"Service Time Fuel (s)\")\n",
    "axs[0,1].set_ylabel(\"Service Time Payment (s)\")\n",
    "\n",
    "axs[0,2].scatter(data[\"Service time Fuel\"], data[\"Shop time\"])\n",
    "axs[0,2].set_xlabel(\"Service Time Fuel (s)\")\n",
    "axs[0,2].set_ylabel(\"Shop Time (s)\")\n",
    "\n",
    "axs[0,3].scatter(data[\"Service time Fuel\"], data[\"Interarrival Times\"])\n",
    "axs[0,3].set_xlabel(\"Service Time Fuel (s)\")\n",
    "axs[0,3].set_ylabel(\"Interarrival Times (s)\")\n",
    "\n",
    "\n",
    "\n",
    "axs[1,0].scatter(data[\"Service time payment\"], data[\"Service time Fuel\"])\n",
    "axs[1,0].set_xlabel(\"Service Time Payment (s)\")\n",
    "axs[1,0].set_ylabel(\"Service Time Fuel (s)\")\n",
    "\n",
    "# Calculate the observed frequencies for each unique value\n",
    "observed_frequencies = data['Service time payment'].value_counts().sort_index()\n",
    "\n",
    "# λ for the Poisson distribution from the data\n",
    "lambda_poisson = data['Service time payment'].mean()\n",
    "\n",
    "# Re-create the Poisson distribution object\n",
    "poisson_dist = stats.poisson(mu=lambda_poisson)\n",
    "\n",
    "# Recalculate the expected Poisson frequencies for each unique value\n",
    "expected_frequencies_poisson = poisson_dist.pmf(observed_frequencies.index) * len(data)\n",
    "\n",
    "# Create a bar chart for the observed frequencies\n",
    "# plt.figure(figsize=(14, 7))\n",
    "n = len(data['Service time payment'])\n",
    "axs[1,1].bar(observed_frequencies.index, observed_frequencies/n, label='Observed Frequencies')\n",
    "\n",
    "# Add a scatter plot for the expected Poisson frequencies\n",
    "axs[1,1].scatter(observed_frequencies.index, expected_frequencies_poisson/n, color='orange', label='Expected Poisson Density', zorder=2)\n",
    "\n",
    "# axs[1,1].hist(data[\"Service time payment\"],bins=20, density=True)\n",
    "axs[1,1].set_xlabel(\"Service Time Payment (s)\")\n",
    "axs[1,1].set_ylabel(\"Density\")\n",
    "# \n",
    "# plot uniform distribution\n",
    "# \n",
    "# x = np.linspace(data[\"Service time payment\"].min(), data[\"Service time payment\"].max())\n",
    "# y_uni = stats.uniform(loc=0, scale=2 * data[\"Service time payment\"].mean()).pdf(x)\n",
    "# \n",
    "# # plot gamma distribution\n",
    "# y_gamma = stats.gamma(a=parameters[\"Service time payment\"][\"Gamma Distribution\"][\"estimated_alpha\"], scale=1 / parameters[\"Service time payment\"][\"Gamma Distribution\"][\"estimated_beta\"]).pdf(x)\n",
    "# \n",
    "# # plot poisson distribution\n",
    "# \n",
    "# y_poisson = stats.poisson.pmf(x, data[\"Service time payment\"].mean())\n",
    "# \n",
    "# axs[1,1].plot(\n",
    "#     x,\n",
    "#     y_uni,\n",
    "#     label=\"Estimated Uniform Distribution\",\n",
    "#     color=\"orange\"\n",
    "#  )\n",
    "# axs[1,1].plot(\n",
    "#     x,\n",
    "#     y_gamma,\n",
    "#     label=\"Estimated Gamma Distribution\",\n",
    "#     color=\"red\"\n",
    "#  )\n",
    "# \n",
    "# # fix this plot\n",
    "# axs[1,1].scatter(\n",
    "#     x,\n",
    "#     y_poisson,\n",
    "#     label=\"Estimated Poisson Distribution\",\n",
    "#     color=\"yellow\"\n",
    "#  )\n",
    "# \n",
    "axs[1,1].legend(loc=\"upper right\")\n",
    "\n",
    "\n",
    "axs[1,2].scatter(data[\"Service time payment\"], data[\"Shop time\"])\n",
    "axs[1,2].set_xlabel(\"Service Time Payment (s)\")\n",
    "axs[1,2].set_ylabel(\"Shop Time (s)\")\n",
    "\n",
    "\n",
    "axs[1,3].scatter(data[\"Service time payment\"], data[\"Interarrival Times\"])\n",
    "axs[1,3].set_xlabel(\"Service Time Payment (s)\")\n",
    "axs[1,3].set_ylabel(\"Interarrival Times (s)\")\n",
    "\n",
    "axs[2,0].scatter(data[\"Shop time\"], data[\"Service time Fuel\"])\n",
    "axs[2,0].set_xlabel(\"Shop Time (s)\")\n",
    "axs[2,0].set_ylabel(\"Service Time Fuel (s)\")\n",
    "\n",
    "axs[2,1].scatter(data[\"Shop time\"], data[\"Service time payment\"])\n",
    "axs[2,1].set_xlabel(\"Shop Time (s)\")\n",
    "axs[2,1].set_ylabel(\"Service Time Payment (s)\")\n",
    "\n",
    "\n",
    "shop_data = data[data[\"Shop time\"] > 0]\n",
    "\n",
    "axs[2,2].hist(shop_data[\"Shop time\"], density=True )\n",
    "axs[2,2].set_xlabel(\"Shop Time (s)\")\n",
    "axs[2,2].set_ylabel(\"Density\")\n",
    "# plot the gamma distribution\n",
    "x = np.linspace(shop_data[\"Shop time\"].min(), shop_data[\"Shop time\"].max())\n",
    "y = stats.gamma(a=parameters[\"Shop time\"][\"Gamma Distribution\"][\"estimated_alpha\"], scale=1 / parameters[\"Shop time\"][\"Gamma Distribution\"][\"estimated_beta\"]).pdf(x)\n",
    "\n",
    "axs[2,2].plot(\n",
    "    x,\n",
    "    y,\n",
    "    label=\"Estimated Gamma Distribution\",\n",
    "    color=\"orange\"\n",
    " )\n",
    "axs[2,2].legend(loc=\"upper right\")\n",
    "\n",
    "\n",
    "axs[2,3].scatter(data[\"Shop time\"], data[\"Interarrival Times\"])\n",
    "axs[2,3].set_xlabel(\"Shop Time (s)\")\n",
    "axs[2,3].set_ylabel(\"Interarrival Times (s)\")\n",
    "\n",
    "\n",
    "\n",
    "axs[3,0].scatter(data[\"Interarrival Times\"], data[\"Service time Fuel\"])\n",
    "axs[3,0].set_xlabel(\"Interarrival Times (s)\")\n",
    "axs[3,0].set_ylabel(\"Service Time Fuel (s)\")\n",
    "\n",
    "axs[3,1].scatter(data[\"Interarrival Times\"], data[\"Service time payment\"])\n",
    "axs[3,1].set_xlabel(\"Interarrival Times (s)\")\n",
    "axs[3,1].set_ylabel(\"Service Time Payment (s)\")\n",
    "\n",
    "\n",
    "\n",
    "axs[3,2].scatter(data[\"Interarrival Times\"], data[\"Shop time\"])\n",
    "axs[3,2].set_xlabel(\"Interarrival Times (s)\")\n",
    "axs[3,2].set_ylabel(\"Shop Time (s)\")\n",
    "\n",
    "axs[3,3].hist( data[\"Interarrival Times\"], density=True)\n",
    "axs[3,3].set_xlabel(\"Interarrival Times (s)\")\n",
    "axs[3,3].set_ylabel(\"Density (s)\")\n",
    "\n",
    "x = np.linspace(data[\"Interarrival Times\"].min(), data[\"Interarrival Times\"].max())\n",
    "y = stats.gamma(a=parameters[\"Interarrival Times\"][\"Gamma Distribution\"][\"estimated_alpha\"], scale=1 / parameters[\"Interarrival Times\"][\"Gamma Distribution\"][\"estimated_beta\"]).pdf(x)\n",
    "\n",
    "axs[3,3].plot(\n",
    "    x,\n",
    "    y,\n",
    "    label=\"Estimated Gamma Distribution\",\n",
    "    color=\"orange\"\n",
    " )\n",
    "axs[3,3].legend(loc=\"upper right\")\n",
    "\n",
    "\n",
    "# set the title to the SPLOM\n",
    "\n",
    "plt.suptitle(\"Scatter Plot Matrix of Gas Station Parameters\".title(), fontsize=30, y= 0.92)\n",
    "plt.savefig(\"/graphs/EDA/scatter_plot_matrix.png\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def left_right_encoder(x):\n",
    "    if x == \"Left\":\n",
    "        return -1\n",
    "    elif x == \"Right\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "data[\"Parking Preference (-1=L, 1=R)\"] = data[\"Parking Preference\"].apply(lambda x: left_right_encoder(x))\n",
    "\n",
    "fig = px.parallel_coordinates(\n",
    "    data_frame=data,\n",
    "    dimensions=[\n",
    "        \"Parking Preference (L=-1, R=1)\",\n",
    "        \"Interarrival Times\",\n",
    "        \"Shop time\",\n",
    "        \"Service time Fuel\",\n",
    "        \"Service time payment\",\n",
    "        \n",
    "    ],\n",
    "    color=\"Arrival Time (H)\",\n",
    "    labels={\n",
    "        # \"Parking Preference (L=-1, R=1)\": \"Parking Preference\",\n",
    "        \"Interarrival Times\": \"Interarrival Times\",\n",
    "        \"Shop time\": \"Shop Time\",\n",
    "        \"Service time Fuel\": \"Service Time Fuel\",\n",
    "        \"Service time payment\": \"Service Time payment\",\n",
    "    },\n",
    "    title=\"Parallel Coordinates Plot\",\n",
    "    color_continuous_scale=\"viridis\",\n",
    ")\n",
    "\n",
    "# save figure\n",
    "fig.write_image(\"parallel_coordinates_plot.png\")\n",
    "\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# plot a histogram of frequency of arrival times in the day\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(data[\"Arrival Time (H)\"], bins=16, edgecolor=\"black\", density=True)\n",
    "\n",
    "ax.set_xlabel(\"Hour of the Day\")\n",
    "ax.set_ylabel(\"Density\")\n",
    "fig.suptitle(\"Distribution of Arrivals in the Day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# plot a histogram of frequency of arrival times in the day\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(data[\"Arrival Time (H)\"], bins=16, edgecolor=\"black\", density=True)\n",
    "\n",
    "ax.set_xlabel(\"Hour of the Day\")\n",
    "ax.set_ylabel(\"Density\")\n",
    "fig.suptitle(\"Distribution of Arrivals in the Day\")\n",
    "fig.savefig(\"/graphs/EDA/arrival_time_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Service Time Payment (include this exploration  in your section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these visualizations,the data does not appear to be strongly multimodal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "fit_uniform_dist = stats.uniform(loc=(data[\"Service time payment\"].min()), scale=data[\"Service time payment\"].max() - data[\"Service time payment\"].min())   \n",
    "test = stats.kstest(data[\"Service time payment\"], fit_uniform_dist.cdf)\n",
    "print(test)\n",
    "\n",
    "m1 = np.mean(data[\"Service time payment\"])\n",
    "fit_poisson_dist = stats.poisson(mu=m1)\n",
    "test = stats.kstest(data[\"Service time payment\"], fit_poisson_dist.cdf)\n",
    "print(test)\n",
    "print(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Checking for multimodality\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(data['Service time payment'], bins=30, kde=True)\n",
    "plt.title('Histogram of Service Time Payments with KDE')\n",
    "plt.xlabel('Service Time Payment')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "\n",
    "# Adding a more detailed Kernel Density Estimate (KDE) plot to help identify potential modes\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.kdeplot(data['Service time payment'], bw_adjust=0.5)\n",
    "plt.title('Kernel Density Estimate (KDE) of Service Time Payments')\n",
    "plt.xlabel('Service Time Payment')\n",
    "plt.ylabel('Density')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The blue bars show the observed frequencies of each unique \"Service time payment\" value. These are the actual counts from the dataset you provided. Each bar's height indicates how many times a particular payment value occurs in the data. For instance, if a bar reaches up to a height of 20, it means that particular service time payment was observed 20 times in the dataset.\n",
    "\n",
    "The red dots represent the expected frequencies for each service time payment value as predicted by a Poisson distribution with a mean equal to the average of the observed data. The height of each red cross corresponds to the number of occurrences that the Poisson distribution would predict for that specific payment value.\n",
    "\n",
    "Based on:\n",
    "1. the visualization below\n",
    "2. the fact that our data set is very small in size\n",
    "3. p value from ks-test\n",
    "\n",
    "we conclude that poisson might be the underlying distribution of the service payment time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Calculate the observed frequencies for each unique value\n",
    "observed_frequencies = data['Service time payment'].value_counts().sort_index()\n",
    "\n",
    "# λ for the Poisson distribution from the data\n",
    "lambda_poisson = data['Service time payment'].mean()\n",
    "\n",
    "# Re-create the Poisson distribution object\n",
    "poisson_dist = stats.poisson(mu=lambda_poisson)\n",
    "\n",
    "# Recalculate the expected Poisson frequencies for each unique value\n",
    "expected_frequencies_poisson = poisson_dist.pmf(observed_frequencies.index) * len(data)\n",
    "\n",
    "# Create a bar chart for the observed frequencies\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.bar(observed_frequencies.index, observed_frequencies, label='Observed Frequencies', color='blue', alpha=0.6)\n",
    "\n",
    "# Add a scatter plot for the expected Poisson frequencies\n",
    "plt.scatter(observed_frequencies.index, expected_frequencies_poisson, color='red', label='Expected Poisson Frequencies', zorder=2)\n",
    "\n",
    "plt.title('Observed vs Expected Poisson Frequencies for Service Time Payments')\n",
    "plt.xlabel('Service Time Payment')\n",
    "plt.ylabel('Frequencies')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
